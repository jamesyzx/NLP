{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/james/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/james/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/james/anaconda3/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.24.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/Users/james/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/james/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------load data------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-98d18f170cc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0my2_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/train.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train.txt'"
     ]
    }
   ],
   "source": [
    "# single-input and multi-output models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, merge, Dense, Activation, Conv2D, Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "print('------------load data------------')\n",
    "y_train = []\n",
    "y2_train = []\n",
    "with open('data/train.txt') as fr:\n",
    "    for i in range(1, 15001):\n",
    "        line = fr.readline().split()\n",
    "        y_train.append(int(line[1]))\n",
    "        y2_train.append([float(line[2]), float(line[3]), float(line[4])])\n",
    "y_train = np.array(y_train)\n",
    "y2_train = np.array(y2_train)\n",
    "print('y_train ok')\n",
    "\n",
    "x_test = []\n",
    "train_str = 'data/test/'\n",
    "for i in range(1, 3001):\n",
    "    img_string = train_str + str(i) + '.jpg'\n",
    "    im = Image.open(img_string).convert(\"L\")\n",
    "    jpg_data = im.getdata()\n",
    "    jpg_data = np.array(jpg_data)\n",
    "    x_test.append(jpg_data)\n",
    "x_test = np.array(x_test)\n",
    "print('x_test ok')\n",
    "\n",
    "y_test = []\n",
    "y2_test = []\n",
    "with open('data/test.txt') as fr:\n",
    "    for i in range(1, 3001):\n",
    "        line = fr.readline().split()\n",
    "        y_test.append(int(line[1]))\n",
    "        y2_test.append([float(line[2]), float(line[3]), float(line[4])])\n",
    "y_test = np.array(y_test)\n",
    "y2_test = np.array(y2_test)\n",
    "print('y_test ok')\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 50 \n",
    "num_classes = 2\n",
    "num_attitude = 3\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 227, 227\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "# x_train = x_train.astype(\"float64\")\n",
    "x_test = x_test.astype(\"float64\")\n",
    "# x_train /= 255\n",
    "x_test /= 255\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "# print('x_train shape:', x_train.shape)\n",
    "# print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# input\n",
    "main_input = Input(shape=input_shape, dtype='float64', name='main_input') \n",
    "# Conv layer 1 output shape (55, 55, 48)\n",
    "conv_1 = Convolution2D(\n",
    "    nb_filter=48,\n",
    "    nb_row=11,\n",
    "    nb_col=11,\n",
    "    subsample=(4, 4),\n",
    "    activation='relu',\n",
    "    name='conv_1',\n",
    "    init='he_normal',\n",
    "    dim_ordering='tf',\n",
    ")(main_input) \n",
    "conv_1 = Dropout(0.25)(conv_1)\n",
    "\n",
    "# Conv layer 2 output shape (27, 27, 128)\n",
    "conv_2 = Convolution2D(\n",
    "    nb_filter=128,\n",
    "    nb_row=5,\n",
    "    nb_col=5,\n",
    "    subsample=(2, 2),\n",
    "    activation='relu',\n",
    "    name='conv_2',\n",
    "    init='he_normal'\n",
    ")(conv_1)\n",
    "conv_2 = Dropout(0.25)(conv_2)\n",
    "\n",
    "# Conv layer 3 output shape (13, 13, 192)\n",
    "conv_3 = Convolution2D(\n",
    "    nb_filter=192,\n",
    "    nb_row=3,\n",
    "    nb_col=3,\n",
    "    subsample=(2, 2),\n",
    "    border_mode='same',\n",
    "    activation='relu',\n",
    "    name='conv_3',\n",
    "    init='he_normal'\n",
    ")(conv_2)\n",
    "conv_3 = Dropout(0.25)(conv_3)\n",
    "\n",
    "# Conv layer 4 output shape (13, 13, 192)\n",
    "conv_4 = Convolution2D(\n",
    "    nb_filter=192,\n",
    "    nb_row=3,\n",
    "    nb_col=3,\n",
    "    border_mode='same',\n",
    "    activation='relu',\n",
    "    name='conv_4',\n",
    "    init='he_normal'\n",
    ")(conv_3)\n",
    "conv_4 = Dropout(0.25)(conv_4)\n",
    "\n",
    "# Conv layer 5 output shape (13, 128, 128)\n",
    "conv_5 = Convolution2D(\n",
    "    nb_filter=128,\n",
    "    nb_row=3,\n",
    "    nb_col=3,\n",
    "    activation='relu',\n",
    "    border_mode='same',\n",
    "    name='conv_5',\n",
    "    init='he_normal'\n",
    ")(conv_4)\n",
    "conv_5 = Dropout(0.25)(conv_5)\n",
    "\n",
    "# fully connected layer 1\n",
    "flat = Flatten()(conv_5)\n",
    "dense_1 = Dense(2048, activation='relu', name='dense_1', init='he_normal')(flat)\n",
    "dense_1 = Dropout(0.25)(dense_1)\n",
    "\n",
    "# fully connected layer 2\n",
    "dense_2 = Dense(2048, activation='relu', name='dense_2', init='he_normal')(dense_1)\n",
    "dense_2 = Dropout(0.25)(dense_2)\n",
    "\n",
    "# output\n",
    "label = Dense(num_classes, activation='softmax', name='label', init='he_normal')(dense_2)\n",
    "attitude = Dense(num_attitude, activation='softmax', name='attitude', init='he_normal')(dense_2)\n",
    "\n",
    "# build CNN model\n",
    "model = Model(input=main_input, output=[label, attitude])\n",
    "\n",
    "# optimizer=SGD\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss={'label':'categorical_crossentropy', 'attitude':'mean_squared_error'}, metrics=['accuracy'], loss_weights={'label':0.5, 'attitude':0.5})\n",
    "print(model.summary())\n",
    "\n",
    "with open('log.text','w') as fw:\n",
    "    train_str = 'data/train/'\n",
    "    for l in range(epochs):\n",
    "        for j in range(0, 150):\n",
    "            x_train = []\n",
    "            for i in range(j * 100 + 1, j * 100 + 101):\n",
    "                img_string = train_str + str(i) + '.jpg'\n",
    "                im = Image.open(img_string).convert(\"L\")\n",
    "                jpg_data = im.getdata()\n",
    "                jpg_data = np.array(jpg_data)\n",
    "                x_train.append(jpg_data)\n",
    "            x_train = np.array(x_train)\n",
    "            x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "            x_train = x_train.astype(\"float64\")\n",
    "            x_train /= 255\n",
    "            model.train_on_batch(x_train, [y_train[j * 100:j * 100 + 100], y2_train[j * 100:j * 100 + 100]])\n",
    "        score = model.evaluate(x_test, [y_test, y2_test])\n",
    "        print('Epochs:', l + 1)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test loss of label:', score[1])\n",
    "        print('Test loss of attitude:', score[2])\n",
    "        print('Test accuracy of label:', score[3])\n",
    "        print('Test accuracy of attitude:', score[4])\n",
    "        fw.write('Epochs:'+ str(l + 1) + '\\n')\n",
    "        fw.write('Test loss:' + str(score[0]) + '\\n')\n",
    "        fw.write('Test loss of label:' + str(score[1]) + '\\n')\n",
    "        fw.write('Test loss of attitude:' + str(score[2]) + '\\n')\n",
    "        fw.write('Test accuracy of label:' + str(score[3]) + '\\n')\n",
    "        fw.write('Test accuracy of attitude:' + str(score[4]) + '\\n')\n",
    "\n",
    "model.save('model_Alexnet3_SGD_50.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
